{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD 6 - 26th of Jan. 2024\n",
    "\n",
    "Faisal Jayousi: jayousi@unice.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward model: the blurring operator\n",
    "\n",
    "In SMLM type data, the acquisition consist of a blurred and noisy image of a molecule sample (the ground truth image). \n",
    "Let $x\\in\\mathbb R^n$ be the ground truth image. The microscope's limitations only permit access to a blurred and noisy version $$y=Ax+\\eta$$\n",
    "where $A:\\mathbb R^n \\longrightarrow \\mathbb R^n$ is the forward blurring operator and $\\eta\\in\\mathbb R^n$ is a Gaussian distributed noisy vector with $0$ mean and variance $\\sigma^2$: $\\eta\\sim\\mathcal N(0,\\sigma^2)$.\n",
    "\n",
    "Given the acquisition $y$, we aim to reconstruct the ground truth $x$. To do so, a thorough understanding of the microscope's functioning is required, and a corresponding forward model must be proposed.\n",
    "\n",
    "* Load the ground truth image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image\n",
    "gt = plt.imread('gt.png')\n",
    "gt = gt[..., 1]\n",
    "gt = gt * 255.\n",
    "\n",
    "# plot the image\n",
    "plt.imshow(gt, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now focus on the blurring operator. Recall that it is inconvenient (and often impossible) to construct the matrix $A$. Multiplying an image with a blurring matrix (huge) can be written as a convolution between the image itself and an appropriate kernel (that has the same size as the image), called Point Spread Function (PSF), since it describes how a point is distorted (and spread) by the microscope. To do so, the Fast Fourier Trasform is used and only the PSF has to be stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let $\\sigma_h=20$. Create the associated Gaussian kernel $h$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution kernel: the point spread function PSF\n",
    "s = 20\n",
    "h = ...\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(np.fft.fftshift(h), cmap='gray')\n",
    "plt.title('PSF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the forward operator using the convolution theorem\n",
    "def forward_operator(x, h):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the blurred imaage\n",
    "blurred_image = forward_operator(gt, h)\n",
    "\n",
    "# plot the ground truth, the PSF and the blurred image\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(131)\n",
    "plt.imshow(gt, cmap='gray')\n",
    "plt.title('Ground truth')\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.fft.fftshift(h), cmap='gray')\n",
    "plt.title('PSF')\n",
    "plt.subplot(133)\n",
    "plt.imshow(blurred_image, cmap='gray')\n",
    "plt.title('Blurred image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to generate a noisy realisation of the blurred image in order to obtain a realistic acquisition. Add some Gaussian noise with $\\sigma=0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this way you will have a deterministic result\n",
    "np.random.seed(24)\n",
    "\n",
    "sigma_noise = 0.1\n",
    "acq = ...\n",
    "\n",
    "# plot the ground truth, the blurred image and the final acquisition (blurred and noisy)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(131)\n",
    "plt.imshow(gt, cmap='gray')\n",
    "plt.title('Ground truth')\n",
    "plt.subplot(132)\n",
    "plt.imshow(blurred_image, cmap='gray')\n",
    "plt.title('Blurred image')\n",
    "plt.subplot(133)\n",
    "plt.imshow(acq, cmap='gray')\n",
    "plt.title('Acquisition')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the Forward-Backward algorithm (ISTA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $y\\in\\mathbb R^n$ be a noisy acquisition and $A:\\mathbb R^n \\longrightarrow \\mathbb R^n$ the blurring operator. To solve the inverse problem i.e. to find $x\\in\\mathbb R^n$ such that $$y=Ax+\\eta$$ We use a variational approach and solve\n",
    "$$ \\operatorname{argmin}_{x\\in\\mathbb R^n} \\frac{1}{2}\\|Ax-y\\|_2^2+\\lambda \\|x\\|_1+\\texttt{i}_{\\ge 0}(x) $$\n",
    "with the Forward-Backward algorithm. The first step of FB algorithm is the forward step: a gradient descent step for the smooth function $f$. \n",
    "\n",
    "Implement a function that computes the gradient of $f$, $\\nabla f(x)= A^T (Ax-y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the gradient of the fidelity term in terms of convolutions\n",
    "def gradient(x, h, y):\n",
    "    return ...  # don't forget to take the real part (np.real())!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute now the Lipschitz constant of $\\nabla f$, recalling that $L=\\|A\\|^2$. This will be needed for choosing a suitable stepsize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the Lipschitz constant Lips\n",
    "Lips = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the soft thresholding function below. This function is needed during the backward step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prox of \\ell_1 norm: soft thresholding function\n",
    "def soft_thresholding(x, gamma):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function that computes the fidelity term $f(x)=\\frac{1}{2}\\|Ax-y\\|_2^2$ and the cost function $F(x)=\\frac{1}{2}\\|Ax-y\\|_2^2+\\lambda \\|x\\|_1$  at each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fidelity\n",
    "def fidelity(x, h, y):\n",
    "    return ...\n",
    "\n",
    "# cost function\n",
    "def cost_function(x, h, y, lmbda):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have now the elements to define the function for the FB algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters\n",
    "# x0 is the initialisation\n",
    "# tau is the stepsize\n",
    "# lambda is the regularisation parameter\n",
    "# y is the acquisition, h is the psf ---> needed to compute the gradient of f at each iteration\n",
    "# epsilon is the tolerance parameter, maxiter is the maximum numer of iterations ---> needed for the stopping criterion\n",
    "\n",
    "def FB(x0, tau, lmbda, y, h, epsilon, maxiter):\n",
    "    xk = x0\n",
    "    cost = np.zeros(maxiter)\n",
    "    norms = np.zeros(maxiter)\n",
    "\n",
    "    for k in np.arange(maxiter):\n",
    "\n",
    "        if (k + 1) % 100 == 0:\n",
    "            print(f'Iter {k+1}/{maxiter}')\n",
    "        # forward step: gradient descent of f\n",
    "        xkk = ...\n",
    "\n",
    "        # backward step\n",
    "        xkk = ...\n",
    "\n",
    "        # positivity constraints\n",
    "        xkk = ...\n",
    "\n",
    "        # compute the cost function\n",
    "        cost[k] = cost_function(xkk, h, y, lmbda)\n",
    "        norms[k] = np.linalg.norm(xkk-xk, 'fro')\n",
    "\n",
    "        # update the iteration\n",
    "        xk = xkk\n",
    "        if np.abs(cost[k] - cost[k-1]) / cost[k] < epsilon:\n",
    "            break\n",
    "    return xk , cost, norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful: define a function to plot reconstruction, cost function and relative changes of the iterates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(rec, cost, norms):\n",
    "    # plot the ground truth, the final acquisition (blurred and noisy) and the reconstruction\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(gt, cmap='gray')\n",
    "    plt.title('Ground truth')\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(acq, cmap='gray')\n",
    "    plt.title('Acquisition')\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(rec, cmap='gray')\n",
    "    plt.title('Reconstruction')\n",
    "    plt.show()\n",
    "\n",
    "    # plot how the cost function decreases and how the iterates converge\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(cost)\n",
    "    plt.xlabel('$k$')\n",
    "    plt.ylabel(\"$F(x_k)$\")\n",
    "    plt.title('Cost function')\n",
    "    plt.subplot(122)\n",
    "    plt.plot(norms)\n",
    "    plt.xlabel('$k$')\n",
    "    plt.ylabel(\"$||x^{(k+1)}-x_{k}||$\")\n",
    "    plt.title('Relative difference in the reconstructions')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that your algorithm is working by computing the reconstruction for the following set of input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.shape(gt)[0]\n",
    "dim = (n, n)\n",
    "x0 = np.zeros(dim)\n",
    "tau = 0.5\n",
    "lmbda = 0.3\n",
    "maxiter = 1000\n",
    "epsilon = 0.001\n",
    "\n",
    "\n",
    "# compute the reconstruction\n",
    "rec, cost, norms = FB(x0, tau, lmbda, acq, h, 0, maxiter)\n",
    "plot_results(rec, cost, norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions: regularisation parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Try different values of the regularisation parameter and see what happens. Can you explain the behaviour of the reconstructions with respect to $\\lambda$? Does the choice of $\\lambda$ affect the reconstruction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = (n, n)\n",
    "x0 = np.zeros(dim)\n",
    "tau = ...\n",
    "maxiter = 1000\n",
    "epsilon = 0\n",
    "\n",
    "# choose some values for lmbda\n",
    "lmbda = [ ]\n",
    "\n",
    "# compute the reconstruction\n",
    "for l in lmbda:\n",
    "    print(f'\\lambda={l}')\n",
    "    rec, cost, norms = FB(x0, tau, l, acq, h, epsilon, maxiter)\n",
    "    plot_results(rec, cost, norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) For example try $\\lambda=0$. What happens? Which algorithm are you actually using in this very particular case? (Look both at the reconstructed image and at the equation defining the model with $\\lambda=0$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec, cost, norms = FB(x0, tau, 0, acq, h, epsilon, maxiter)\n",
    "plot_results(rec, cost, norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions: step-size\n",
    "To answer the following questions set $\\lambda=0.3$, $maxiter = 1000$, $\\epsilon = 0$ and $x_0=0$.\n",
    "\n",
    "3) Try a very small stepsize and observe how the cost function decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = (n, n)\n",
    "x0 = np.zeros(dim)\n",
    "tau = 0.01\n",
    "maxiter = ...\n",
    "epsilon = ...\n",
    "lmbda = ...\n",
    "\n",
    "rec, cost, norms = FB(x0, tau, lmbda, acq, h, epsilon, maxiter)\n",
    "plot_results(rec, cost, norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Then try $\\tau=\\frac{1}{Lips}$. What do you observe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = (n, n)\n",
    "x0 = np.zeros(dim)\n",
    "tau = ...\n",
    "maxiter = ...\n",
    "epsilon = ...\n",
    "lmbda = ...\n",
    "\n",
    "rec, cost, norms = FB(x0, tau, lmbda, acq, h, epsilon, maxiter)\n",
    "plot_results(rec, cost, norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Then try $\\tau>>\\frac{1}{Lips}$. What do you observe? \n",
    "\n",
    "(Hint: plot the cost functions in the three cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = (n, n)\n",
    "x0 = np.zeros(dim)\n",
    "tau = ...\n",
    "maxiter = ...\n",
    "epsilon = ...\n",
    "lmbda = ...\n",
    "\n",
    "rec, cost, norms = FB(x0, tau, lmbda, acq, h, epsilon, maxiter)\n",
    "plot_results(rec, cost, norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Towards more complex regularisation functions\n",
    "We now consider the following optimisation problem $$ \\min_{x\\in\\mathbb R^n} \\frac{1}{2}\\|Ax-y\\|_2^2+\\lambda\\mathcal{R}_{\\alpha,\\beta}(x)+\\texttt{i}_{\\ge 0}(x) $$\n",
    "where $$\\mathcal{R}_{\\alpha,\\beta}(x) = \\|x\\|_1+\\langle\\alpha,x\\rangle+\\beta, \\qquad \\alpha\\in\\mathbb{R}^n, \\beta>0$$\n",
    "* Complete the functions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_prox(x, tau, alpha, beta):\n",
    "    \"\"\"\n",
    "    prox operator of R(x)\n",
    "    \"\"\"\n",
    "    return\n",
    "\n",
    "\n",
    "def new_cost_function(x, h, y, lmbda, alpha, beta):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modify the FB function accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters\n",
    "# x0 is the initialisation\n",
    "# tau is the stepsize\n",
    "# lambda is the regularisation parameter\n",
    "# y is the acquisition, h is the psf ---> needed to compute the gradient of f at each iteration\n",
    "# epsilon is the tolerance parameter, maxiter is the maximum numer of iterations ---> needed for the stopping criterion\n",
    "\n",
    "def FB(x0, tau, lmbda, y, h, epsilon, maxiter):\n",
    "    return xk, cost, norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Test the new FB function using the following parameters and interpret the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = (n, n)\n",
    "x0 = np.zeros(dim)\n",
    "tau = 0.5\n",
    "lmbda = 0.09\n",
    "maxiter = 1000\n",
    "epsilon = 0.001\n",
    "alpha = np.random.randn(*dim)\n",
    "beta = 7*np.pi\n",
    "\n",
    "\n",
    "rec, cost, norms = FB(x0, tau, lmbda, acq, h, epsilon, maxiter)\n",
    "plot_results(rec, cost, norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the impact of $\\beta$ on the reconstruction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "27a969663b44205c0470047d97abda994390bcaabf7398117902358deea6e5c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
