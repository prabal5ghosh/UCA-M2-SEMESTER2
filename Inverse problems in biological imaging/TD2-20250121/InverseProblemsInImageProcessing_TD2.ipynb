{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1cae665e",
   "metadata": {},
   "source": [
    "## Inverse problems in image processing - TD 2\n",
    "                                  \n",
    "                                  e-mail: jayousi@unice.fr\n",
    "                                  date: 19th Jan. 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de4718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d791fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(img):\n",
    "    return ((img - img.min())/(img.max() - img.min()) * 255)\n",
    "\n",
    "def snr(xref, x):\n",
    "    return 20 * np.log10(np.linalg.norm(xref) / np.linalg.norm(xref-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b81b40",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcef50e",
   "metadata": {},
   "source": [
    "## 1.1 Fourier Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f7cf06",
   "metadata": {},
   "source": [
    "Load and display the two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fefecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the images\n",
    "x1 = np.float64(plt.imread('barbara.png'))\n",
    "x2 = np.float64(plt.imread('cells.png'))\n",
    "\n",
    "# rescale the images in the range 0-255\n",
    "x1 = scale(x1)\n",
    "x2 = scale(x2)\n",
    "\n",
    "# plot the images\n",
    "plt.figure(figsize=(8, 4), dpi=80)\n",
    "plt.subplot(121)\n",
    "plt.imshow(x1, cmap='gray')\n",
    "plt.title('Barbara')\n",
    "plt.subplot(122)\n",
    "plt.imshow(x2, cmap='gray')\n",
    "plt.title('Cells')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7172cb9",
   "metadata": {},
   "source": [
    "* Compute the FFT (Fast Fourier Transform) of the Barbara image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701fcfb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9e7e430",
   "metadata": {},
   "source": [
    "## 1.2 Noise Generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d343ee36",
   "metadata": {},
   "source": [
    "Add noise, $\\eta$, to the \"Barbara\" image where\n",
    "\n",
    "$$\\eta \\sim \\mathcal{N}(0, \\sigma^2 I)$$\n",
    "\n",
    "Plot the original and the noisy image.  \n",
    "\n",
    "_Hint_: you can use the np.random.randn() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = 150                     # SD of Gaussian noise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e8eebb7",
   "metadata": {},
   "source": [
    "* Compute the SNR between \"Barbara\" and its noisy version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0fb0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe2ca0bd",
   "metadata": {},
   "source": [
    "## 1.3 Image Blurring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d7295fd",
   "metadata": {},
   "source": [
    "We consider an image model where the observed image $y$ is a result of a degradation of an image $x$ by a linear transformation $f$, i.e.\n",
    "\n",
    "$$\n",
    "mat(y)=f(mat(x))\n",
    "$$\n",
    "\n",
    "where $mat(\\cdot)$ is a notation used in this lab to underline that $f(mat(x))$ is an operation on a matrix $x$. \n",
    "\n",
    "Here $x$ and $y$ are images of size $512 \\times 512$, then  $x\\in \\mathbb{R}^{512\\times512}$ and  $y\\in \\mathbb{R}^{512\\times512}$.\n",
    "\n",
    "A common degradation is the blurring, achieved by convolving the image $x$ with a low-pass Gaussian filter kernel $h$. The blurred image $y$ is given by:\n",
    "\n",
    "$$\n",
    "mat(y)=mat(h)*mat(x) \n",
    "$$.\n",
    "\n",
    "A common notation  is the matrix/vector notation:\n",
    "\n",
    "$$\n",
    "y= A x\n",
    "$$\n",
    "\n",
    "where $A$  is the matrix that does the convolution of the image $x$ by the Gaussian filter $h$. Here, $y$ and $x$ is the vectorized form of the images $mat(y)$ and $mat(x)$ respectiverly, in the lexical order. Then, $y\\in \\mathbb{R}^{N\\times 1}$ and $x\\in \\mathbb{R}^{N\\times 1}$ where $N$ is the number of pixels. It is important, as we will observe in the lab, that even though we use the notation for $A$, we do not actually construct the matrix. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90891baf",
   "metadata": {},
   "source": [
    "As you just observed, it is not always wise to create the full matrix $A$. So we will start by creating the function $f(mat(x))=mat(h)*mat(x)$, where $*$ denotes the convolution. Since convolution in time corresponds to multiplication in the frequency domain, we will do the convolution in the Fourier domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d4c627",
   "metadata": {},
   "source": [
    "Compute the low pass Gaussian kernel with $\\sigma=5$ pixels.  \n",
    "\n",
    "The steps to create the convolution kernel is: \n",
    "1. Create a meshgrid of same size of the image (512x512). The center of the meshgrid could be 0. \n",
    "2. Apply the the Gaussian function onto the grid, and normalize the response such that the sum of all elements in the reponse =1. \n",
    "3. Apply the Fast Fourier Transformation. NOTE: If the center of the grid was defined as 0, a fftshift has to be done before applying the FFT2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87226f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 5\n",
    "n = x1.shape[0]\n",
    "t = np.concatenate( (np.arange(0, n/2+1), np.arange(-n/2, -1)) )\n",
    "\n",
    "Y, X = np.meshgrid(t, t)\n",
    "h = np.exp( -(X**2+Y**2)/(2.0*float(sigma)**2) )\n",
    "h = h / np.sum(h)\n",
    "hf = np.real(np.fft.fft2(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b04f67",
   "metadata": {},
   "source": [
    "Plot the convolution kernel before and after the fourier transform in the Fourier domain.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e314c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), dpi=80)\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.fft.fftshift(h), cmap='gray')\n",
    "plt.title('PSF')\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.fft.fftshift(hf), cmap='gray')\n",
    "plt.title('OTF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7770e8cb",
   "metadata": {},
   "source": [
    "Compute the blurred image using periodic convolution with FFTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f178898",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_bl = np.real(np.fft.ifft2(hf * np.fft.fft2(x1)))\n",
    "\n",
    "plt.figure(figsize=(6, 4), dpi=80)\n",
    "plt.subplot(121)\n",
    "plt.imshow(x1, cmap='gray')\n",
    "plt.title('Original')\n",
    "plt.subplot(122)\n",
    "plt.imshow(y1_bl, cmap='gray')\n",
    "plt.title('Blurry')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c6a908",
   "metadata": {},
   "source": [
    "# 2. Introduction to Inverse Problems"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "588ed2a6",
   "metadata": {},
   "source": [
    "A more realistic model writes\n",
    "$$\n",
    "mat(y)=f(mat(x)) + mat(\\eta) \\qquad (1)\n",
    "$$\n",
    "where $mat(\\cdot)$ is a notation used in this lab to underline that $f(mat(x))$ is an operation on a matrix $x$. \n",
    "\n",
    "A more common notation to write (1) is: \n",
    "$$\n",
    "y= Ax + \\eta\n",
    "$$\n",
    "where $A$ is the linear transformation and $x$, $y$ and $\\eta$ are viewed as vectors. However, when working in image processing the matrix $A$ will rearly be constructed, and we will not reshape the image $x$ as a vector.  It is important, as we have observed in the lab, that even though we use the notations $A$, we do not actually construct the matrix. \n",
    "\n",
    "In this lab, we considerer that the noise, $\\eta$ follows a multidimensional normal law of covarience $\\sigma^2 I$ and of mean the zero vector. So, we can write: $\\eta \\sim \\mathcal{N}(0, \\sigma^2 I)$. \n",
    "  \n",
    "The probability density function $p(\\eta)$ is written as: \n",
    "\\begin{equation}\n",
    " p(\\eta) = \\frac{1}{(2\\pi\\sigma^2)^{\\frac{N}{2}}} \\exp \\left(-\\frac{\\|\\eta\\|_2^2}{2\\sigma^2}\\right)\n",
    "\\end{equation}\n",
    " where $N$ is the number of pixels and $\\|\\eta\\|_p$ is the $l^p$-norm defined as: \n",
    "\\begin{equation}\n",
    "  \\|\\eta\\|_p = \\left(\\sum_{i=1}^N |\\eta|^p\\right)^{\\frac{1}{p}}\n",
    "\\end{equation}\n",
    " \n",
    " We want to find the unknown image $x$ from the observation $y$. Therefore, we use the  maximum likelihood estimation which maximizes the likelihood $L(y,x)$ with respect to the unknown image $x$. This likelihood is equal to the conditional probability of $y$ knowing $x$, denoted $p_{y|x}(y|x)$. The probability is calculated from the image model, supposing that the $\\eta$ is white Gaussian noise. \n",
    "\n",
    "More precisely, the likelihood $L(y,x)$ is given by:\n",
    "\\begin{equation}\n",
    " L(y,x) = p_{y|x}(y|x) = p_n(n=Ax - y) = \\frac{1}{(2\\pi\\sigma^2)^{\\frac{N}{2}}} \\textrm{exp}\\left(-\\frac{\\|Ax-y\\|_2^2}{2\\sigma^2}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "We search for an estimation $\\hat{x}$ of the real image $x$ by maximizing the ligelihood  $L(y,x)$ as follows: \n",
    "\\begin{equation}\n",
    " \\hat{x} = \\arg\\max_x L(y,x)\n",
    "\\end{equation}\n",
    "\n",
    "In order to avoid the difficulties related to the exponential, we often maximize the logarithm of the likelihood (which does not change the maximum argument since the logarithm is strictly increasing):\n",
    "\\begin{equation}\n",
    " \\hat{x} = \\arg\\max_x \\, \\ln(L(y,x)) = \\arg\\max_x \\, \\left(- \\ln \\left(2\\pi\\sigma^2 \\right)^{\\frac{N}{2}} -\\frac{1}{2\\sigma^2}\\|Ax-y\\|_2^2\\right)\n",
    "\\end{equation}\n",
    "\n",
    "The term $- \\ln \\left( 2\\pi\\sigma^2 \\right)^{\\frac{N}{2}}$ is a constant with respect to $x$, and thus does not intervene in the estimation of $\\arg\\max$. Therefore, we can write:\n",
    "\\begin{equation}\n",
    " \\hat{x} = \\arg\\max_x \\, \\left( -\\frac{1}{2\\sigma^2}\\|Ax-y\\|_2^2\\right)\n",
    "\\end{equation}\n",
    "\n",
    "The last step removes the proptionality coefficent $\\frac{1}{2\\sigma^2}$ and the negative sign by using the fact that  $\\arg\\max_x -f(x) = \\arg\\min_x f(x)$. So, finally: \n",
    "\n",
    "\\begin{equation*}\n",
    " \\hat{x} = \\arg\\min_x \\, \\|Ax-y\\|_2^2 \n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b21dd1d",
   "metadata": {},
   "source": [
    "Denote $J(x)=\\|Ax-y\\|_2^2 $. This term is in fact the Least Square term associated to the system $y = Ax$. The gradient of $J$ is $\\nabla J(x)= 2A^*(Ax-y)$, where $A^*$ is the adjoint operator of A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284970ea",
   "metadata": {},
   "source": [
    "In order to find the minimum, instead of using Exact Least Square solution, we can make use of the gradient descent algorithm. The algorithm can be written as:\n",
    "\n",
    "\\begin{equation}\n",
    " x_{k+1} = x_k - \\alpha 2 A^*(A x_k - y)\n",
    "\\end{equation}\n",
    "\n",
    "with $k = 0 \\dots K-1$, $x_0 = y$ and $0 < \\alpha \\leq \\frac{1}{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29662a52",
   "metadata": {},
   "source": [
    "## 2.1 Deconvolution Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6520e181",
   "metadata": {},
   "source": [
    "Let $y$ be a blured image (without adding any noise). Compute the exact solution $\\hat{x}$ that satisfies $\\nabla J(\\hat{x})=0$, using FFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245b2d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7236299a",
   "metadata": {},
   "source": [
    "Add white Gaussian noise ($\\sigma=10$) to the blurred image $y$ of the previous question. Compute again the exact solution $\\hat{x}$ that satisfies $\\nabla J(\\hat{x})=0$, using FFT. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb8d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9829bb9",
   "metadata": {},
   "source": [
    "#### Gradient Descent algorithm\n",
    "In order to find the minimum, instead of using Exact Least Square solution, we can make use of the gradient descent algorithm. Recall that it is an iterative algorithm, where each update is given by:\n",
    "\n",
    "\\begin{equation}\n",
    " x_{k+1} = x_k - \\alpha 2 A^*(A x_k - y)\n",
    "\\end{equation}\n",
    "\n",
    "with $k = 0 \\dots K-1$, $x_0 = y$ and $0 < \\alpha \\leq \\frac{1}{2}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96e11188",
   "metadata": {},
   "source": [
    "Complete the gradient descent function below, plot the cost/error function along with the resulting image. Ensure that the cost function consistently decreases (debug your code if necessary!). What observations can you make for different values of K?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef2930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Gradient Descent algo\n",
    "\n",
    "#-- Parameters\n",
    "alpha = 0.4                   # Step\n",
    "K = 500                       # Number of iterations\n",
    "\n",
    "# Initialisation\n",
    "xk = ...\n",
    "J = np.zeros(shape=(K))    # Cost\n",
    "err = np.zeros(shape=(K))  # Error\n",
    "\n",
    "# Main loop\n",
    "k = 0\n",
    "while k < K:\n",
    "    #  gradient\n",
    "    gradJ = ...\n",
    "    # update xk\n",
    "    xk = xk - alpha*gradJ\n",
    "    # Calculate cost and Error\n",
    "    J[k] = np.linalg.norm(np.real(np.fft.ifft2(hf*np.fft.fft2(xk)) - ...))**2  #  Cost function\n",
    "    err[k] = np.linalg.norm(xk-x1)  # error between xk and the original image\n",
    "    k += 1\n",
    "\n",
    "\n",
    "# -- plots\n",
    "# plot x\n",
    "plt.subplot(121)\n",
    "plt.imshow(x1, cmap='gray')\n",
    "plt.title('Original')\n",
    "# plot xk\n",
    "plt.subplot(122)\n",
    "plt.imshow(xk, cmap= 'gray')\n",
    "plt.title('Restored Image')\n",
    "plt.show()\n",
    "\n",
    "# Estimation Error\n",
    "plt.figure()\n",
    "plt.semilogy(np.log(err))\n",
    "plt.title('Estimation Error')\n",
    "\n",
    "# Cost Function\n",
    "plt.figure()\n",
    "plt.plot(J)\n",
    "plt.title('Cost function evolution')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08091ce0",
   "metadata": {},
   "source": [
    "* Write your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703fcad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78914caa",
   "metadata": {},
   "source": [
    "### Tikhonov regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe1132",
   "metadata": {},
   "source": [
    "\n",
    "We now consider the following penalised criterion $$\\mathcal{J}(x):= \\|Ax-y\\|_2^2 + \\lambda\\mathcal{R}(x)$$ where $\\mathcal{R}(\\cdot)$ is a regularisation term. \n",
    "\n",
    "\n",
    "* Explain why this term is introduced.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682eb651",
   "metadata": {},
   "source": [
    "**Write your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78ac6f2",
   "metadata": {},
   "source": [
    "We consider these two regularisation terms in this lab: \n",
    "\\begin{align*}\n",
    "    \\mathcal{R}_1(x) &=  \\|x\\|_2^2 \\\\\n",
    "    \\mathcal{R}_2(x) &=  \\|\\nabla x\\|_2^2\n",
    "\\end{align*}\n",
    "where $\\lambda>0$ is a regularisation parameter that controls the weight of the regularisation, and $$\\|\\nabla x \\|_2 = \\sum_{i,j}((\\nabla x)_{i,j})^2$$\n",
    "with\n",
    "\\begin{align}\n",
    "&(\\nabla x)_{i,j} = \\big( (\\nabla x)_{i,j}^1,(\\nabla x)_{i,j}^2 \\big)\\\\\n",
    "&(\\nabla x)_{i,j}^1 = (x_{i+1,j}-x_{i,j})\\quad\\text{if}\\quad i<N,\\qquad 0 \\quad\\text{if}\\quad i=N \\\\\n",
    "&(\\nabla x)_{i,j}^2 = (x_{i,j+1}-x_{i,j})\\quad\\text{if}\\quad j<N,\\qquad 0 \\quad\\text{if}\\quad j=N \\\\\n",
    "\\end{align}\n",
    "where $N \\times N$ is the size of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5f2b7e",
   "metadata": {},
   "source": [
    "* Compute their gradients and then complete the following python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a798c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_1(x):\n",
    "    return\n",
    "\n",
    "def grad_reg_1(x):\n",
    "    return\n",
    "\n",
    "def reg_2(x):\n",
    "    return\n",
    "\n",
    "def grad_reg_2(x):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b217b915",
   "metadata": {},
   "source": [
    "* Modify the Gradient Descent function slightly to take into account $\\mathcal{R}_1(\\cdot)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf8b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Gradient Descent algo (R_1(.))\n",
    "\n",
    "#-- Parameters\n",
    "alpha = 0.4                   # Step\n",
    "K = 400                       # Number of iterations\n",
    "lambd = 0.005\n",
    "\n",
    "# Initialisation\n",
    "xk_tn = ...  # tikhonov-nograd initialisation\n",
    "J = np.zeros(shape=(K))    # Cost\n",
    "err = np.zeros(shape=(K))  # Error\n",
    "\n",
    "# Main loop\n",
    "k = 0\n",
    "while k < K:\n",
    "    #  gradient\n",
    "    fidelity_grad = ...\n",
    "    gradJ = fidelity_grad + lambd * grad_reg_1(xk_tn)\n",
    "    # update xk\n",
    "    xk_tn = xk_tn - alpha*gradJ\n",
    "    # Calculate cost and Error\n",
    "    J[k] = np.linalg.norm(np.real(np.fft.ifft2(hf*np.fft.fft2(xk_tn))-...))**2 + lambd*reg_1(xk_tn)  #  Cost function\n",
    "    err[k] = np.linalg.norm(xk_tn-x1)  # error between xk and the original image\n",
    "    k += 1\n",
    "\n",
    "\n",
    "# -- plots\n",
    "# plot x\n",
    "plt.subplot(121)\n",
    "plt.imshow(x1, cmap='gray')\n",
    "plt.title('Original')\n",
    "# plot xk\n",
    "plt.subplot(122)\n",
    "plt.imshow(xk_tn, cmap= 'gray')\n",
    "plt.title('Restored Image')\n",
    "plt.show()\n",
    "\n",
    "# Estimation Error\n",
    "plt.figure()\n",
    "plt.semilogy(np.log(err))\n",
    "plt.title('Estimation Error')\n",
    "\n",
    "# Cost Function\n",
    "plt.figure()\n",
    "plt.plot(J)\n",
    "plt.title('Cost function evolution')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98548d7",
   "metadata": {},
   "source": [
    "* Modify the Gradient Descent function slightly to take into account $\\mathcal{R}_2(\\cdot)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Gradient Descent algo (R_2(.))\n",
    "\n",
    "#-- Parameters\n",
    "alpha = 0.4                   # Step\n",
    "K = 400                       # Number of iterations\n",
    "lambd = 0.01\n",
    "\n",
    "# Initialisation\n",
    "xk_tg = y1\n",
    "J = np.zeros(shape=(K))    # Cost\n",
    "err = np.zeros(shape=(K))  # Error\n",
    "\n",
    "# Main loop\n",
    "k = 0\n",
    "while k < K:\n",
    "   #  gradient\n",
    "    fidelity_grad = 2*np.real(np.fft.ifft2(hf_adj*np.fft.fft2(np.fft.ifft2(hf*np.fft.fft2(xk_tg))-y1)))\n",
    "\n",
    "\n",
    "    gradJ = fidelity_grad + lambd * grad_reg_2(xk_tg)\n",
    "    # update xk\n",
    "    xk_tg = xk_tg - alpha*gradJ\n",
    "    # Calculate cost and Error\n",
    "    J[k] = np.linalg.norm(np.real(np.fft.ifft2(hf*np.fft.fft2(xk_tg))-y1))**2 + lambd*reg_2(xk_tn) #  Cost function\n",
    "    err[k] = np.linalg.norm(xk_tg-x1)  # error between xk and the original image\n",
    "    k += 1\n",
    "\n",
    "\n",
    "# -- plots\n",
    "# plot x\n",
    "plt.subplot(121)\n",
    "plt.imshow(x1, cmap='gray')\n",
    "plt.title('Original')\n",
    "# plot xk\n",
    "plt.subplot(122)\n",
    "plt.imshow(xk_tg, cmap= 'gray')\n",
    "plt.title('Restored Image')\n",
    "plt.show()\n",
    "\n",
    "# Estimation Error\n",
    "plt.figure()\n",
    "plt.semilogy(np.log(err))\n",
    "plt.title('Estimation Error')\n",
    "\n",
    "# Cost Function\n",
    "plt.figure()\n",
    "plt.plot(J)\n",
    "plt.title('Cost function evolution')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542ff6dc",
   "metadata": {},
   "source": [
    "* Modify $\\lambda$ to observe the influence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b98298",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19e0d035",
   "metadata": {},
   "source": [
    "* Observe the restored images, and compare them to the true image by computing the SNR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f398e82b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "27a969663b44205c0470047d97abda994390bcaabf7398117902358deea6e5c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
